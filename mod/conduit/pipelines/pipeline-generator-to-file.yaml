version: "2.2"
pipelines:
  - id: example-pipeline
    status: running
    name: "generator-to-file"
    connectors:
      - id: example-source
        type: source
        plugin: "generator"
        settings:
          # The amount of time the generator is generating records in a burst.
          # Has an effect only if `burst.sleepTime` is set.
          # Type: duration
          # Optional
          burst.generateTime: '1s'
          # The time the generator "sleeps" between bursts.
          # Type: duration
          # Optional
          burst.sleepTime: ""
          # The options for the `raw` and `structured` format types. It accepts
          # pairs of field names and field types, where the type can be one of:
          # `int`, `string`, `time`, `bool`, `duration`.
          # Type: string
          # Optional
          collections.*.format.options.*: ""
          # Path to the input file (only applicable if the format type is
          # `file`).
          # Type: string
          # Optional
          collections.*.format.options.path: ""
          # The format of the generated payload data (raw, structured, file).
          # Type: string
          # Optional
          collections.*.format.type: ""
          # Comma separated list of record operations to generate. Allowed
          # values are "create", "update", "delete", "snapshot".
          # Type: string
          # Required
          collections.*.operations: 'create'
          # The options for the `raw` and `structured` format types. It accepts
          # pairs of field names and field types, where the type can be one of:
          # `int`, `string`, `time`, `bool`, `duration`.
          # Type: string
          # Optional
          format.options.*: ""
          # Path to the input file (only applicable if the format type is
          # `file`).
          # Type: string
          # Optional
          format.options.path: ""
          # The format of the generated payload data (raw, structured, file).
          # Type: string
          # Optional
          format.type: ""
          # Comma separated list of record operations to generate. Allowed
          # values are "create", "update", "delete", "snapshot".
          # Type: string
          # Required
          operations: 'create'
          # The maximum rate in records per second, at which records are
          # generated (0 means no rate limit).
          # Type: float
          # Optional
          rate: ""
          # The time it takes to 'read' a record. Deprecated: use `rate`
          # instead.
          # Type: duration
          # Optional
          readTime: ""
          # Number of records to be generated (0 means infinite).
          # Type: int
          # Optional
          recordCount: ""
          # Maximum delay before an incomplete batch is read from the source.
          # Type: duration
          # Optional
          sdk.batch.delay: '0'
          # Maximum size of batch before it gets read from the source.
          # Type: int
          # Optional
          sdk.batch.size: '0'
          # Specifies whether to use a schema context name. If set to false, no
          # schema context name will be used, and schemas will be saved with the
          # subject name specified in the connector (not safe because of name
          # conflicts).
          # Type: bool
          # Optional
          sdk.schema.context.enabled: 'true'
          # Schema context name to be used. Used as a prefix for all schema
          # subject names. If empty, defaults to the connector ID.
          # Type: string
          # Optional
          sdk.schema.context.name: ""
          # Whether to extract and encode the record key with a schema.
          # Type: bool
          # Optional
          sdk.schema.extract.key.enabled: 'true'
          # The subject of the key schema. If the record metadata contains the
          # field "opencdc.collection" it is prepended to the subject name and
          # separated with a dot.
          # Type: string
          # Optional
          sdk.schema.extract.key.subject: 'key'
          # Whether to extract and encode the record payload with a schema.
          # Type: bool
          # Optional
          sdk.schema.extract.payload.enabled: 'true'
          # The subject of the payload schema. If the record metadata contains
          # the field "opencdc.collection" it is prepended to the subject name
          # and separated with a dot.
          # Type: string
          # Optional
          sdk.schema.extract.payload.subject: 'payload'
          # The type of the payload schema.
          # Type: string
          # Optional
          sdk.schema.extract.type: 'avro'
      - id: example-destination
        type: destination
        plugin: "file"
        settings:
          # Path is the file path used by the connector to read/write records.
          # Type: string
          # Required
          path: ""
          # Maximum delay before an incomplete batch is written to the
          # destination.
          # Type: duration
          # Optional
          sdk.batch.delay: '0'
          # Maximum size of batch before it gets written to the destination.
          # Type: int
          # Optional
          sdk.batch.size: '0'
          # Allow bursts of at most X records (0 or less means that bursts are
          # not limited). Only takes effect if a rate limit per second is set.
          # Note that if `sdk.batch.size` is bigger than `sdk.rate.burst`, the
          # effective batch size will be equal to `sdk.rate.burst`.
          # Type: int
          # Optional
          sdk.rate.burst: '0'
          # Maximum number of records written per second (0 means no rate
          # limit).
          # Type: float
          # Optional
          sdk.rate.perSecond: '0'
          # The format of the output record. See the Conduit documentation for a
          # full list of supported formats
          # (https://conduit.io/docs/using/connectors/configuration-parameters/output-format).
          # Type: string
          # Optional
          sdk.record.format: 'opencdc/json'
          # Options to configure the chosen output record format. Options are
          # normally key=value pairs separated with comma (e.g.
          # opt1=val2,opt2=val2), except for the `template` record format, where
          # options are a Go template.
          # Type: string
          # Optional
          sdk.record.format.options: ""
          # Whether to extract and decode the record key with a schema.
          # Type: bool
          # Optional
          sdk.schema.extract.key.enabled: 'true'
          # Whether to extract and decode the record payload with a schema.
          # Type: bool
          # Optional
          sdk.schema.extract.payload.enabled: 'true'
